import streamlit as st
from PIL import Image
import requests
from io import BytesIO
import torch
import torchvision.transforms as transforms
import numpy as np
import segmentation_models_pytorch as smp
import matplotlib.pyplot as plt
import os
import pandas as pd

st.markdown("""
     <style>

    /* –°–∫—Ä—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ "Pages" */
    [data-testid="stSidebar"] > div:first-child > div:first-child > h2 {
        display: none;
    }
    
    /* –°–∫—Ä—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü */
    [data-testid="stSidebar"] > div:first-child > div:nth-child(2) {
        display: none;
    }
    
    /* –ï—Å–ª–∏ –Ω—É–∂–Ω–æ ‚Äî —Å–∫—Ä—ã–≤–∞–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å */
    [data-testid="stSidebar"] > div:first-child > hr {
        display: none;
    }        
    
    /* –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä ‚Äî –ù–ï –Ω–∞ –≤–µ—Å—å —ç–∫—Ä–∞–Ω, –∞ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º */
    .block-container {
        max-width: 1300px !important;   /* ‚Üê –∫–ª—é—á–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä */
        padding: 2rem 2rem !important;
        margin: 0 auto;                 /* —Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ–º */
    }

    /* –§–æ–Ω —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –º–æ—Ä–µ) */
    .stApp {
        background-image: url("https://balthazar.club/o/uploads/posts/2024-01/1705040959_balthazar-club-p-krasivii-fon-lesa-oboi-46.jpg");
        background-size: cover;
        background-position: center;
        background-attachment: fixed;
        background-repeat: no;
    }

    /* –¢—ë–º–Ω—ã–µ –∫–∞—Ä—Ç–æ—á–∫–∏ —Å –±–µ–ª—ã–º —Ç–µ–∫—Å—Ç–æ–º */
    .css-1v0mbdj, .css-12w0y3b, .stMarkdown, .stTabs, .stDataFrame, 
    .stPlotlyChart, .stImage, .stTable, div[data-testid="stHorizontalBlock"] {
        background-color: rgba(35, 54, 35, 0.88) !important;
        color: #f1f5f9 !important;
        padding: 1.2rem;
        border-radius: 14px;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
    }

    /* –¢–µ–∫—Å—Ç */
    .stMarkdown h1, .stMarkdown h2, .stMarkdown h3, .stMarkdown h4, 
    .stMarkdown p, .stMarkdown li {
        color: #f1f5f9 !important;
    }

    /* –í–∫–ª–∞–¥–∫–∏ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
        padding: 10px 0;
    }
    .stTabs [data-baseweb="tab"] {
        height: 45px;
        background-color: rgba(35, 54, 35, 0.6);
        border-radius: 10px 10px 0 0;
        color: #cbd5e1;
        font-weight: 600;
        padding: 0 24px;
        border: none;
    }
    .stTabs [aria-selected="true"] {
        background-color: #345533;
        color: #e2e8f0;
    }

    /* –ì—Ä–∞—Ñ–∏–∫–∏ matplotlib ‚Äî –Ω–µ –≤—ã—Ö–æ–¥—è—Ç –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã */
    .stPlotlyChart, .stPyplot {
        overflow: hidden;
    }
    </style>
""", unsafe_allow_html=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (—Ç—ë–º–Ω–∞—è —Ç–µ–º–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî –∫—Ä–∞—Å–∏–≤–µ–µ –¥–ª—è –º–∞—Å–æ–∫)
st.set_page_config(page_title="–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ª–µ—Å–∞", layout="centered")

# –í–∫–ª–∞–¥–∫–∏
tab1, tab2 = st.tabs(["üå≤ –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è", "üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"])

with tab1:
    st.title("üå≤ –î–µ—Ç–µ–∫—Ç–æ—Ä –ª–µ—Å–∞ –Ω–∞ –∞—ç—Ä–æ—Ñ–æ—Ç–æ—Å–Ω–∏–º–∫–∞—Ö")
    st.markdown("–ó–∞–≥—Ä—É–∂–∞–π—Ç–µ —Ñ–æ—Ç–æ –∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É ‚Äî –º–æ–¥–µ–ª—å –ø–æ–∫–∞–∂–µ—Ç, –≥–¥–µ –ª–µ—Å.")

    MODEL_PATH = "models/best_unet.pth"

    @st.cache_resource
    def load_model():
        if not os.path.exists(MODEL_PATH):
            st.error(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞! –ü–æ–ª–æ–∂–∏—Ç–µ '{MODEL_PATH}' —Ä—è–¥–æ–º —Å app.py")
            return None, None

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        model = smp.Unet(
            encoder_name="efficientnet-b4",
            encoder_weights=None,
            in_channels=3,
            classes=1,
            activation=None
        )
        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
        model.to(device)
        model.eval()
        return model, device

    model, device = load_model()

    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])

    def segment_image(image_pil):
        if model is None:
            return None, 0.0, 0.0
    
        img_tensor = transform(image_pil).unsqueeze(0).to(device)
        with torch.no_grad():
            output = model(img_tensor)
            probs = torch.sigmoid(output)[0, 0].cpu().numpy()


        orig_w, orig_h = image_pil.size

        # –í—ã–±–∏—Ä–∞–µ–º –ø–æ—Ä–æ–≥ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞
        if orig_w > 800 and orig_h > 800:
            threshold = 0.6
        else:
            threshold = 0.3
        
        mask = (probs > threshold).astype(np.uint8) * 255
        forest_percent = (probs > threshold).mean() * 100
        confidence = probs.mean() * 100
        return mask, forest_percent, confidence

    # === –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ ===
    st.header("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    uploaded_files = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ç–æ (JPG/PNG)", 
        accept_multiple_files=True, 
        type=['png', 'jpg', 'jpeg']
    )

    if uploaded_files:
        for uploaded_file in uploaded_files:
            image = Image.open(uploaded_file).convert("RGB")

            # –û—Ä–∏–≥–∏–Ω–∞–ª
            st.image(image, caption=f"–û—Ä–∏–≥–∏–Ω–∞–ª: {uploaded_file.name}", width=700)

            # –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–∏–∂–µ
            mask, forest_percent, confidence = segment_image(image)

            if mask is not None:
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ matplotlib ‚Äî —É–±–∏—Ä–∞–µ–º –±–µ–ª—ã–π —Ñ–æ–Ω –∏ –æ—Å–∏
                plt.figure(figsize=(10, 10))
                plt.imshow(image)
                plt.imshow(mask, cmap="Greens", alpha=0.6)
                plt.axis('off')
                plt.margins(0, 0)
                plt.tight_layout(pad=0)

                st.pyplot(plt, use_container_width=True)  # –±–µ–∑ –±–µ–ª–æ–≥–æ –æ–∫–Ω–∞

                st.success("**–†–µ–∑—É–ª—å—Ç–∞—Ç:**")
                st.write(f"üå≤ –õ–µ—Å –∑–∞–Ω–∏–º–∞–µ—Ç **{forest_percent:.1f}%** –ø–ª–æ—â–∞–¥–∏")
                st.write(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: **{confidence:.1f}%**")
                st.markdown("---")  # —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏

    # === –ü–æ URL ===
    st.header("–í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–æ—Ç–æ")
    url = st.text_input("–ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞:")

    if url:
        try:
            response = requests.get(url, timeout=15)
            response.raise_for_status()
            image = Image.open(BytesIO(response.content)).convert("RGB")

            st.image(image, caption="–û—Ä–∏–≥–∏–Ω–∞–ª –ø–æ —Å—Å—ã–ª–∫–µ", width=700)

            mask, forest_percent, confidence = segment_image(image)

            plt.figure(figsize=(10, 10))
            plt.imshow(image)
            plt.imshow(mask, cmap="Greens", alpha=0.6)
            plt.axis('off')
            plt.margins(0, 0)
            plt.tight_layout(pad=0)

            st.pyplot(plt, use_container_width=True)

            st.success("**–†–µ–∑—É–ª—å—Ç–∞—Ç:**")
            st.write(f"üå≤ –õ–µ—Å –∑–∞–Ω–∏–º–∞–µ—Ç **{forest_percent:.1f}%** –ø–ª–æ—â–∞–¥–∏")
            st.write(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: **{confidence:.1f}%**")

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")

with tab2:
    st.header("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏")

    st.write("**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**")
    st.write("üîπ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: SMP UNet (EfficientNet-B4 backbone)")
    st.write("üîπ –≠–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è: 20")
    st.write("üîπ –û–±—É—á–µ–Ω–∞ –Ω–∞ 5100 –æ–±—ä–µ–∫—Ç–æ–≤")
    st.write("üîπ Loss: BCEWithLogitsLoss")
    st.write("üîπ PR AUC: 0.94")

    metrics_csv = "metrics/training_metrics.csv"
    metrics_png = "metrics/training_plots.png"

    if os.path.exists(metrics_csv):
        df = pd.read_csv(metrics_csv)
        st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ —ç–ø–æ—Ö–∞–º")
        st.dataframe(df.style.format("{:.4f}"))

    if os.path.exists(metrics_png):
        st.subheader("–ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è")
        st.image(Image.open(metrics_png), width=1000)

st.caption("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ª–µ—Å–∞ –Ω–∞ –∞—ç—Ä–æ—Ñ–æ—Ç–æ—Å–Ω–∏–º–∫–∞—Ö.")

st.sidebar.title('–ù–∞–≤–∏–≥–∞—Ü–∏—è üß≠')
st.sidebar.page_link('app.py', label='Forest Segmentation', icon='üå≤')
st.sidebar.page_link('pages/face.py', label='Detector Face', icon='üëÅÔ∏è')
st.sidebar.page_link('pages/sudno.py', label='Detector Ships', icon='‚õ¥Ô∏è')
# st.sidebar.page_link('pages/analysis.py', label='–ê–Ω–∞–ª–∏–∑', icon='üìä')